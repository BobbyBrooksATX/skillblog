<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

  <title>Notes on Regression - Method of Moments</title>
  <meta property="og:title" content="Notes on Regression - Method of Moments" />
  <meta name="twitter:title" content="Notes on Regression - Method of Moments" />
  <meta name="description" content="Another way of establishing the OLS formula is through the method of moments approach. This method supposedly goes way back to Pearson in 1894. It could be thought of as replacing a population moment with a sample analogue and using it to solve for the parameter of interest.
Example 1To find an estimator for the sample mean, \(\mu=E[X]\), one replaces the expected value with a sample analogue, \(\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n} X_{i} = \bar{X}\)">
  <meta property="og:description" content="Another way of establishing the OLS formula is through the method of moments approach. This method supposedly goes way back to Pearson in 1894. It could be thought of as replacing a population moment with a sample analogue and using it to solve for the parameter of interest.
Example 1To find an estimator for the sample mean, \(\mu=E[X]\), one replaces the expected value with a sample analogue, \(\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n} X_{i} = \bar{X}\)">
  <meta name="twitter:description" content="Another way of establishing the OLS formula is through the method of moments approach. This method supposedly goes way back to Pearson in 1894. It could be thought of as replacing a population moment …">
  <meta name="author" content="Timothy Lin"/>
  <meta name="twitter:card" content="summary" />
  <meta property="og:url" content="/2017/08/31/notes-on-regression-method-of-moments/" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="Quasilinear Musings" />

  <meta name="generator" content="Hugo 0.30.2" />
  <link rel="canonical" href="/2017/08/31/notes-on-regression-method-of-moments/" />
  <link rel="alternate" href="/index.xml" type="application/rss+xml" title="Quasilinear Musings">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css" integrity="sha384-wITovz90syo1dJWVh32uuETPVEtGigN07tkttEqPv+uR2SE/mbQcG7ATL28aI9H0" crossorigin="anonymous">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
  <link rel="stylesheet" href="/css/main.css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" />
  <link rel="stylesheet" href="/css/pygment_highlights.css" />
  <link rel="stylesheet" href="/css/highlight.min.css" />



<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-100201704-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>

</head>

  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Quasilinear Musings</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="Blog" href="/post/">Blog</a>
            </li>
          
        
          
            <li>
              <a title="About" href="/about/">About</a>
            </li>
          
        
          
            <li>
              <a title="SG-Dashboard" href="/dashboard/sg-dashboard/">SG-Dashboard</a>
            </li>
          
        
          
            <li>
              <a title="Resources" href="/resources/">Resources</a>
            </li>
          
        
          
            <li>
              <a title="Tags" href="/tags">Tags</a>
            </li>
          
        

        

        
      </ul>
    </div>

    <div class="avatar-container">
      <div class="avatar-img-border">
        
      </div>
    </div>

  </div>
</nav>




    
  
  
  




  

  <header class="header-section ">
    
    <div class="intro-header no-img">
      
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              <h1>Notes on Regression - Method of Moments</h1>
                
                
                  <span class="post-meta">
  Posted on August 31, 2017
  
</span>


                
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>


    
<div class="container">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <p>Another way of establishing the OLS formula is through the method of moments approach. This method supposedly goes way back to Pearson in 1894. It could be thought of as replacing a population moment with a sample analogue and using it to solve for the parameter of interest.</p>
<div id="example-1" class="section level3">
<h3>Example 1</h3>
<p>To find an estimator for the sample mean, <span class="math inline">\(\mu=E[X]\)</span>, one replaces the expected value with a sample analogue, <span class="math inline">\(\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n} X_{i} = \bar{X}\)</span></p>
</div>
<div id="example-2" class="section level3">
<h3>Example 2</h3>
<p>Let <span class="math inline">\(X_{1}, X_{2}, ..., X_{n}\)</span> be drawn from a normal distribution i.e. <span class="math inline">\(X_{i} \sim N(\mu,\sigma^{2})\)</span>
The goal is to find an estimator for the two parameters, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. The first and second moment of a normal distribution is given by:</p>
<p><span class="math display">\[
\begin{aligned}
E[X] &amp;= \mu \\
E[X^{2}] &amp;= \mu_{2} = \mu^{2} + \sigma^{2}
\end{aligned}
\]</span>
An estimator for <span class="math inline">\(\mu\)</span> is easy and is simply <span class="math inline">\(\hat{\mu} = \frac{1}{n}\sum_{i=1}^{n} X_{i} = \bar{X}\)</span>.</p>
<p>Replace the moment condition with the sample analogue and substitute in the estimator for <span class="math inline">\(\mu\)</span> to find an estimator for <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{1}{n}\sum_{i=1}^{n} X_{i}^{2} &amp;= \mu^{2} + \hat{\sigma}^{2} \\
\hat{\sigma}^{2} &amp;= \frac{1}{n}\sum_{i=1}^{n} X_{i}^{2} - \bar{X}^{2} \\
&amp;= \frac{1}{n}\sum_{i=1}^{n}(X_{i}-\bar{X})^2
\end{aligned}
\]</span></p>
</div>
<div id="example-3" class="section level3">
<h3>Example 3</h3>
<p>Let <span class="math inline">\(X_{1}, X_{2}, ..., X_{n}\)</span> be drawn from a poisson distribution i.e. <span class="math inline">\(X_{i} \sim Poisson(\lambda)\)</span>. The poisson distribution is characterised by the following equality: <span class="math inline">\(E[X]=var(X)=\lambda\)</span>. This gives rise to two possible estimators for <span class="math inline">\(\lambda\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\lambda}_{1} &amp;= \bar{X} \\
\hat{\lambda}_{2} &amp;= \frac{1}{n}\sum_{i=1}^{n}(X_{i}-\bar{X})^2
\end{aligned}
\]</span>
Since there is only one parameter to be estimated but two moment conditions, one would need some way of ‘combining’ the two conditions. Using only one condition would be not making full use of the information at hand.</p>
</div>
<div id="regression---method-of-moments" class="section level3">
<h3>Regression - Method of Moments</h3>
<p>More generally, one can write the moment conditions as a vector of functions <span class="math inline">\(g(X_{i},\beta)\)</span>, where <span class="math inline">\(\mathbf{X}_{i}\)</span> is the observed data, including all variables <span class="math inline">\((y_{i}, X_{i})\)</span> and instruments <span class="math inline">\((\mathbf{Z}_{i})\)</span> in the regression model, while <span class="math inline">\(\beta\)</span> is the vector of parameters of length <span class="math inline">\(k\)</span>. The model is identified if the solution is unique, i.e. <span class="math inline">\(Eg(X_{i},\beta)=0\)</span> and <span class="math inline">\(Eg(X_{i},\hat{\beta})=0\)</span> imply that <span class="math inline">\(\beta=\hat{\beta}\)</span>. This requires that we have at least <span class="math inline">\(k\)</span> restrictions for <span class="math inline">\(k\)</span> parameters.</p>
<p>For the OLS regression, one can use the moment condition <span class="math inline">\(E(\mathbf{X}_{i}U_{i})=0\)</span> or <span class="math inline">\(E(\mathbf{X_{i}}(y_{i}-\mathbf{X}_{i}&#39;\beta))=0\)</span> to solve for the usual OLS estimator.</p>
<p>The idea can be carried over to other more complicated regression models. For example, in the case where <span class="math inline">\(g(X_{i},\beta)\)</span> is linear in <span class="math inline">\(\beta\)</span> i.e. <span class="math inline">\(g(X_{i},\beta) = \mathbf{Z}_{i}(y_{i} - \mathbf{X}_{i}&#39;\beta)\)</span> or <span class="math inline">\(E(\mathbf{Z}_{i}U_{i})=0\)</span>, and the model is perfectly identified <span class="math inline">\((l=k)\)</span>, solving the moment condition yields the formula for the IV regression:</p>
<p><span class="math display">\[
\begin{aligned}
0 &amp;= \sum_{i=1}^{n}\mathbf{Z}_{i}(y_{i} - \mathbf{X}_{i}&#39;\hat{\beta}^{IV})  \\
\hat{\beta}^{IV} &amp;= \Big(\sum_{i=1}^{n} \mathbf{Z}_{i}\mathbf{X}_{i}&#39; \Big)^{-1} \sum_{i=1}^{n}\mathbf{Z}_{i}y_{i} \\
&amp;= (\mathbf{Z}&#39;\mathbf{X})^{-1}\mathbf{Z}&#39;\mathbf{y}
\end{aligned}
\]</span></p>
<p>Hence an IV regression could be thought of as substituting ‘problematic’ OLS moments for hopefully better moment conditions with the addition of instruments.</p>
</div>
<div id="extension---generalised-method-of-moments-gmm" class="section level3">
<h3>Extension - Generalised Method of Moments (GMM)</h3>
<p>While it is not possible to identify <span class="math inline">\(\beta\)</span> if there are too few restrictions, one could still identify <span class="math inline">\(\beta\)</span> if there are <span class="math inline">\(l &gt; k\)</span> restrictions (overidentified), as seen in the poisson example.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> One might then wonder what is the best way to combine these restrictions. The GMM approach, introduced by Hansen in 1982, finds an estimate of <span class="math inline">\(\beta\)</span> that brings the sample moments as close to zero as possible. Note that the moment conditions for all the restrictions are still equal to zero, but the sample approximation, being drawn from a finite sample, may not be equal to zero. In other words, the GMM estimator is defined as the value of <span class="math inline">\(\beta\)</span> that minimizes the weighted distance of <span class="math inline">\(\frac{1}{n}\sum_{i=1}^{n}g(X_{i},\beta)\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\beta}^{GMM} &amp;= \arg \min_{\beta \in B} \Big\lVert \frac{1}{n}\sum_{i=1}^{n}g(X_{i},\beta)  \Big\rVert^{2}_{W}  \\
&amp;= \arg \min_{\beta \in B} \Big( \frac{1}{n}\sum_{i=1}^{n}g(X_{i},\beta) \Big)&#39;\mathbf{W} 
\Big( \frac{1}{n}\sum_{i=1}^{n}g(X_{i},\beta) \Big)
\end{aligned}
\]</span>
where <span class="math inline">\(\mathbf{W}\)</span> is the <span class="math inline">\(l \times l\)</span> matrix of weights which is used to select the ideal linear combination of instruments. In the case of the regression model where <span class="math inline">\(g(X_{i},\beta)\)</span> is linear in <span class="math inline">\(\beta\)</span> but is overidentified, the general GMM formula can be found by minimising the above condition and is given by:</p>
<p><span class="math display">\[
\hat{\beta}^{GMM} = \Big((\mathbf{X}&#39;\mathbf{Z})\mathbf{W}(\mathbf{Z}&#39;\mathbf{X}) \Big)^{-1}
(\mathbf{X}&#39;\mathbf{Z})\mathbf{W}(\mathbf{Z}&#39;\mathbf{y})
\]</span></p>
<p>Note that when <span class="math inline">\(\mathbf{W}=(\mathbf{Z}&#39;\mathbf{Z})^{-1}\)</span>, <span class="math inline">\(\hat{\beta}^{GMM}=\hat{\beta}^{IV}\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Please google efficient GMM, for more information on the optimal choice of the weighting matrix.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>In the case of regressions, this happens when there are more instruments than endogenous regressors.<a href="#fnref1" class="footnote-back">↩</a></p></li>
<li id="fn2"><p>This also shows that the 2SLS estimator is a GMM estimator for the linear model. <span class="math inline">\(\mathbf{W}=(\mathbf{Z}&#39;\mathbf{Z})^{-1}\)</span> is also the most efficient estimator if the errors are homoskedastic. In general, there may be other more efficient choices of the weighting matrix.<a href="#fnref2" class="footnote-back">↩</a></p></li>
</ol>
</div>

      </article>

      <ul class="pager blog-pager">
        
          <li class="previous">
            <a href="/2017/08/29/mapping-the-distribution-of-religious-beliefs-in-singapore/" data-toggle="tooltip" data-placement="top" title="Mapping the Distribution of Religious Beliefs in Singapore">&larr; Previous Post</a>
          </li>
        
        
          <li class="next">
            <a href="/2017/09/10/examining-the-changes-in-religious-beliefs-part-2/" data-toggle="tooltip" data-placement="top" title="Examining the Changes in Religious Beliefs - Part 2">Next Post &rarr;</a>
          </li>
        
      </ul>

      

    </div>
  </div>
</div>

    <footer>
  <div class="container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
                <a href="mailto:timothy.lin@alumni.ubc.ca" title="Email me">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://github.com/timlrx" title="GitHub">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
                <a href="https://linkedin.com/in/timothy-lin-0600ba141" title="LinkedIn">
                  <span class="fa-stack fa-lg">
                    <i class="fa fa-circle fa-stack-2x"></i>
                    <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          <li>
            <a href="/index.xml" title="RSS">
              <span class="fa-stack fa-lg">
                <i class="fa fa-circle fa-stack-2x"></i>
                <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
              </span>
            </a>
          </li>
          
        </ul>
        <p class="credits copyright text-muted">
          Timothy Lin
          &nbsp;&bull;&nbsp;
          2018

          
            &nbsp;&bull;&nbsp;
            <a href="/">Quasilinear Musings</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="http://gohugo.io">Hugo v0.30.2</a> powered &nbsp;&bull;&nbsp; Theme by <a href="http://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a> adapted to <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a>
          
        </p>
      </div>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.js" integrity="sha384-/y1Nn9+QQAipbNQWU65krzJralCnuOasHncUFXGkdwntGeSvQicrYkiUBwsgUqc1" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/contrib/auto-render.min.js" integrity="sha384-dq1/gEHSxPZQ7DdrM82ID4YVol9BYyU7GbWlIwnwyPzotpoc57wDw/guX8EaYGPx" crossorigin="anonymous"></script>
<script src="https://code.jquery.com/jquery-1.12.4.min.js" integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script> hljs.initHighlightingOnLoad(); </script>
<script> renderMathInElement(document.body); </script>






  </body>
</html>

