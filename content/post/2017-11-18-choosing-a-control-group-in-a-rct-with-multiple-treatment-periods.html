---
title: Choosing a Control Group in a RCT with Multiple Treatment Periods
author: Timothy Lin
date: '2017-11-18'
slug: choosing-a-control-group-in-a-rct-with-multiple-treatment-periods
categories: []
tags: ['R','notes', 'simulation', 'metrics']
---



<p>Came across a fun little problem over the past few weeks that is related to the topic of policy impact evaluation - a long time interest of mine! Here’s the setting: we have a large population of individuals and a number of treatments that we want to gauge the effectiveness of. The treatments are not necessarily the same but are targeted towards certain sub-segments in the population. Examples of such situations include online ad targeting or marketing campaigns. This gives rise to the following 3 methods of selecting the treatment and control groups:</p>
<ol style="list-style-type: decimal">
<li><p>Apply the targeting rule to get a population subset. Split this group into treatment and control, run the treatment and collect the results. In the next time period, keep those which remain in the control as the control and top up the group with a random sample to maintain a similar proportion of treated and control individuals.</p></li>
<li><p>Randomly split the population into treatment and control. For each period, do not vary the control group. Just administer the treatment on the treatment group. Evaluate the effectiveness of each period on the control group applying the targeting rule to subset the relevant control population.</p></li>
<li><p>For each period and campaign, apply the targeting rule and randomise the group into treatment and control.</p></li>
</ol>
<div id="framework" class="section level3">
<h3>Framework</h3>
<p>Would these methods give equivalent results? I will use the Neyman-Rubin causal framework to formalise the intended goal and outcomes. Let <span class="math inline">\(Y_{i}\)</span> denote the outcome of an individual (e.g. total spending). The fundamental problem of inference is that one would never be able to observe the spending of an individual if he was administered the treatment <span class="math inline">\(Y_{1i}\)</span> or if he was not <span class="math inline">\(Y_{0i}\)</span>. Here, <span class="math inline">\(Y_{1i}\)</span> and <span class="math inline">\(Y_{0i}\)</span> are referred to as potential outcomes as only one outcome can be observed but not the other.</p>
<p>The average effect of a treatment on an individual is given by: <span class="math display">\[
E[Y_{1i} - Y_{0i}]
\]</span></p>
<p>Let <span class="math inline">\(D_{i}=1\)</span> denote being treated and <span class="math inline">\(D_{i}=0\)</span> being not treated. We can look at the difference in average outcomes based on treatment status: <span class="math display">\[
E[Y_{i} \vert D_{i}=1] - E[Y_{i} \vert D_{i}=0] = E[Y_{1i} \vert D_{i}=1] - E[Y_{0i} \vert D_{i}=0]
\]</span></p>
<p>If the treatment is not randomly assigned (e.g. people can choose to take-up the treatment), the above expression can be written as: <span class="math display">\[
\begin{aligned}
E[Y_{i} \vert D_{i}=1] - E[Y_{i} \vert D_{i}=0] &amp;= E[Y_{1i} \vert D_{i}=1] - E[Y_{0i} \vert D_{i}=1]   \\
&amp;+ E[Y_{0i} \vert D_{i}=1] - E[Y_{0i} \vert D_{i}=0]
\end{aligned}
\]</span> The first term on the right is the average treatment effect on treated while the second is the selection bias. For example, if the advertisement has a positive impact on spending then we would expect the second term to be positive leading to an upward bias in its estimated effect.</p>
<p>And that’s precisely why to evaluate the effectiveness of a treatment, we have to randomise people into treatment and control groups. Under randomisation, the potential outcomes are independent of the treatment<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>, <span class="math display">\[
\{Y_{1i}, Y_{0i}\} \perp D_{i} 
\]</span> and</p>
<p><span class="math display">\[
E[Y_{1i} \vert D_{i}=1] - E[Y_{0i} \vert D_{i}=0] = E[Y_{1i} - Y_{0i}]
\]</span> This implies that taking the difference between the average across the treated and control group will give us the <em>Average Treatment Effect (ATE)</em>. In many situations, we relax the assumption by only allowing the mean of non-treated individuals to be independent of treatment status:</p>
<p><span class="math display">\[
E[Y_{1i} \vert D_{i}=1] - E[Y_{0i} \vert D_{i}=0] = E[Y_{1i} - Y_{0i} \vert D_{i}=1]
\]</span> This gives the <em>Average Treatment on Treated (ATT)</em>.</p>
</div>
<div id="thought-experiment" class="section level3">
<h3>Thought Experiment</h3>
<p>To consider the various scenarios outlined above, let me setup a little thought experiment. In my world, there are two types of customers, high type or low type, which I denote by <span class="math inline">\(X_{i}\)</span>. Low type customers, <span class="math inline">\(X_{i} = L\)</span>, spend <span class="math inline">\(\alpha + \epsilon_{it}\)</span> dollars while high type customers, <span class="math inline">\(X_{i} = H\)</span>, spend <span class="math inline">\(\alpha + \beta + \epsilon_{it}\)</span> dollars, where <span class="math inline">\(\epsilon_{it}\)</span> is a drawn from a normal distribution. The treatment of interest is a marketing promotion which is targeted at high spending individuals. Assume low type customers are not affected by the marketing promotion while high type customers have a <span class="math inline">\(p\%\)</span> probability of spending an additional <span class="math inline">\(\delta\)</span> dollars which persist for the rest of the periods. Having taken up the treatment, the high type individual will no longer subscribe to future promotions. I ignore any changes in spending across time periods, though in practice one way to account for such changes is to consider the first difference.</p>
</div>
<div id="simulation-setup" class="section level3">
<h3>Simulation Setup</h3>
<p>To check on the effectiveness of the 3 methods of selecting a control group, let’s do a little simulation with the following parameters: <span class="math display">\[
\begin{aligned}
\alpha &amp;= 3, \\
\beta &amp;=2,   \\
\delta &amp;=1, \\
p &amp;=0.3, \\ 
\epsilon_{it} &amp;\sim N(0,1) ~\forall i 
\end{aligned}
\]</span></p>
<p>To start, let’s build a 3 period model with 100,000 people in the population (half high type and half low type). I consider observations in 3 period, <span class="math inline">\(t=1,2,3\)</span> and split the population into 80% treatment and 20% control. The treatment is targeted towards higher spending individuals. However, one cannot observe the underlying type distribution and has to segment the population by the amount which they spend. In the simulation, I use a spending rule (<span class="math inline">\(Y_{i} &gt; 4\)</span>), which covers approximately 50% of the initial population.</p>
<pre class="r"><code>n= 1e5
p = 0.3
d = 1

df = data.frame(ind = seq(1, n),
                type = rep(c(0,1), n/2),
                epsilon = rnorm(n, 0, 1),
                unif = runif(n, 0, 1),
                unif2 = runif(n, 0, 1))

df$spend = ifelse(df$type==0, 3, 5) + df$epsilon

### Select treatment and control using unif
df$target = ifelse(df$spend&gt;4 , 1, 0)
df$treat = ifelse(df$target==1 &amp; df$unif&lt;0.8, 1, 0)
df$control = ifelse(df$target==1 &amp; df$unif&gt;=0.8, 1, 0)</code></pre>
</div>
<div id="att" class="section level3">
<h3>ATT</h3>
<p>Despite covering 50% of the population, randomness in spending patterns implies that the target group would still consist of both low and high types. This means that the outcome of our experiment would only yield an ATT effect, or the effect on the sub-population who spend more than 4. Let us calculate this effect before using the simulation to verify the results. We are interested in finding the fraction of population who are high type conditional on spending more than 4. First, let us calculate the probability that a high and low type individual spend more than 4 using r’s pnorm function before calculating the conditional probability:</p>
<pre class="r"><code>1-pnorm(4, 3, 1)</code></pre>
<pre><code>## [1] 0.1586553</code></pre>
<pre class="r"><code>1-pnorm(4, 5, 1)</code></pre>
<pre><code>## [1] 0.8413447</code></pre>
<p><span class="math display">\[
\begin{aligned}
P(X_{i}=H \vert Y_{i}&gt;4) &amp;= \frac{P(X_{i}=H, Y_{i}&gt;4)}{P(Y_{i} &gt;4)} \\
&amp;= \frac{0.841*0.5}{0.159*0.5 + 0.841 *0.5} \\
&amp;= 0.841
\end{aligned}
\]</span> Since only 0.841 of the sub-population would be affected by the treatment, we would expect that the average treatment effect would be <span class="math inline">\(0.841*0.3 = 0.25\%\)</span></p>
<pre class="r"><code>### Add in treatment effect to treated
df$delta = ifelse(df$treat==1 &amp; df$type==1 &amp; runif(n, 0, 1)&lt;=p, d, 0)
df$spend2 = df$delta + df$spend

### Average treatment effect on treated
df_subset = df[df$target==1,]
mean(df[df$treat==1,]$spend2) - mean(df[df$control==1,]$spend2)</code></pre>
<pre><code>## [1] 0.2522621</code></pre>
<pre class="r"><code>lm(spend2 ~ treat, data=df_subset)</code></pre>
<pre><code>## 
## Call:
## lm(formula = spend2 ~ treat, data = df_subset)
## 
## Coefficients:
## (Intercept)        treat  
##      5.1682       0.2523</code></pre>
<p>More generally, a better approach to check our result would be to loop over many random samples and find the central tendency of the parameter estimate:</p>
<pre class="r"><code>att &lt;- function(n=1e5, p=0.3, d=1){
  df = data.frame(ind = seq(1, n),
                  type = rep(c(0,1), n/2),
                  epsilon = rnorm(n, 0, 1),
                  unif = runif(n, 0, 1),
                  unif2 = runif(n, 0, 1))
  df$spend = ifelse(df$type==0, 3, 5) + df$epsilon
  
  ### Select treatment and control using unif
  df$target = ifelse(df$spend&gt;4 , 1, 0)
  df$treat = ifelse(df$target==1 &amp; df$unif&lt;0.8, 1, 0)
  df$control = ifelse(df$target==1 &amp; df$unif&gt;=0.8, 1, 0)
  ### Add in treatment effect to treated
  df$delta = ifelse(df$treat==1 &amp; df$type==1 &amp; runif(n, 0, 1)&lt;=p, d, 0)
  df$spend2 = df$delta + df$spend
  ### Average treatment effect on treated
  df_subset = df[df$target==1,]
  mean(df[df$treat==1,]$spend2) - mean(df[df$control==1,]$spend2)
  mod &lt;- lm(spend2 ~ treat, data=df_subset)
  return(coef(mod)[&quot;treat&quot;])
}

B = 500
coef_list = list()
for(b in 1:B){
  coef_list[[b]] &lt;- att()
}

hist(unlist(coef_list))</code></pre>
<p><img src="/post/2017-11-18-choosing-a-control-group-in-a-rct-with-multiple-treatment-periods_files/figure-html/attrepeat-1.png" width="672" /></p>
<pre class="r"><code>mean(unlist(coef_list))</code></pre>
<pre><code>## [1] 0.2512682</code></pre>
<p>Unsurprisingly, the empirical results tally with our mathematical derivation.</p>
</div>
<div id="nd-period-att" class="section level3">
<h3>2nd period ATT</h3>
<p>Now, we are ready to evaluate the various proposed control groups. To keep things simple, the 2nd marketing promotion will be the same as the first and target individuals who spend above 4. However, this time to evaluate the results we need to consider 3 groups - low type, high type takers and high type non-takers - where takers and non-takers refer to whether they responded positively to the treatment in the first period. Repeating the above calculations and focusing on the share of non-takers in the sub-population: <span class="math display">\[
\begin{aligned}
P(X_{i,t=2}=H_{nt} \vert Y_{i,t=2}&gt;4) &amp;= P(X_{i,t=2}=H_{nt} \vert Y_{i,t=2}&gt;4, i \in treated_{t=1}) + P(X_{i,t=2}=H_{nt} \vert Y_{i,t=2}&gt;4, i \in control_{t=1})\\
&amp;=\frac{P(X_{i,t=2}=H_{nt}, Y_{i,t=2}&gt;4)}{P(Y_{i,t=2} &gt;4)}*0.8 + 0.841*0.2 \\
&amp;= \frac{0.841*0.5*0.7}{0.159*0.5 + 0.841 *0.5*0.7 + + 0.841 *0.5*0.3} *0.8 + 0.841*0.2\\
&amp;= 0.639 \\
\\
ATT_{t=2} &amp;= 0.639*0.3  \\
&amp;= 0.192
\end{aligned}
\]</span> The calculations make intuitive sense. With a smaller pool of customers who would respond positively to the treatment, the ATT in the second period is lower than the first.</p>
</div>
<div id="targeting-rule-with-top-up" class="section level3">
<h3>Targeting rule with top-up</h3>
<p>Here’s a few lines of code to implement the idea of trying to keep the members of the control group relatively similar and do a random top-up where necessary.</p>
<pre class="r"><code>### 2nd time period
df$target2 = ifelse(df$spend2&gt;4, 1, 0)
n_control2 = round(sum(df$target2) * 0.2)
n_control_remain = sum(df$target2 &amp; df$control==1)
unif_threshold = (n_control2 - n_control_remain) / (sum(df$target2) - n_control_remain)
df$control2 = ifelse(df$target2==1 &amp; (df$control==1 | df$unif2&lt;=unif_threshold), 1, 0)
### Approximately fill up
df$treat2 = ifelse(df$target2==1 &amp; df$control2==0, 1, 0)
df$delta2 = ifelse(df$treat2==1 &amp; df$type==1 &amp; df$delta==0 &amp; runif(n, 0, 1)&lt;=p, d, 0)
df$spend3 = df$delta2 + df$spend2  + rnorm(n,0,1)

### Average treatment effect 2 (Less than predicted!)
df_subset2 = df[df$target2==1,]
lm(spend3 ~ treat2, data=df_subset2)</code></pre>
<p>I show the results from 500 runs of the above code extracting the coefficient of the supposed treatment effect as well as the proportion of high non-treated individuals from the treatment and control group.</p>
<pre class="r"><code>mean(unlist(coef_list))</code></pre>
<pre><code>## [1] 0.4286825</code></pre>
<pre class="r"><code>mean(unlist(prop_control_list))</code></pre>
<pre><code>## [1] 0.8406825</code></pre>
<pre class="r"><code>mean(unlist(prop_treat_list))</code></pre>
<pre><code>## [1] 0.5889522</code></pre>
<p>Notice that the proportion of high non-treated individuals are no longer the same across the groups and the estimated effect is much larger than the calculated value. Almost no one has been treated in the control group. This leads to an upwards bias in the estimated treatment effect since the coefficient estimate is combining the effect of both the first and second treatment together.</p>
<p>More generally, the extent and direction of bias cannot be so easily quantified. If one allows the spending amounts to have a component that evolves randomly across time, it is possible for the estimate to be smaller than its actual value.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
</div>
<div id="additional-thoughts" class="section level3">
<h3>Additional Thoughts</h3>
<p>Method 2 of having a universal control group is actually a special case of the above problem, where the control group does not vary at all. Under the assumption that each treatment would have a positive effect, the estimated effect for each subsequent treatment would always be overstated.</p>
<p>Only method 3 would give us a sensible result across both periods of the treatment. Here’s a fun little exercise - try to implement a random sample on the second period after subsetting the population using the targeting rule. Do you get a result similar to the calculated ATT above?</p>
</div>
<div id="tldr" class="section level3">
<h3>TL;DR</h3>
<p>In short, when it comes to choosing a random control group in a policy evaluation setting with multiple treatments and periods, the best option is the simplest one. Random assignment always works, no need to over complicate things.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>More accurately only mean independence is required.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Keeping only members that were present in the control group of the previous time period introduces a selection bias.<a href="#fnref2">↩</a></p></li>
</ol>
</div>
